require(outliers) #
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = TRUE)
# merge wide dataset
bigData <- data.frame(AQ10, RAADS14, BCIS15,MCQ_CAT, MCQ_EMO, META)
# skip rows with NaNs
bigData_clean <- na.omit(bigData)
# Meta Menta similar effect on ASD
OneSystem.model <- 'fASD =~ AQ10 + RAADS14
fHOC =~ MCQ_EMO + MCQ_CAT + META
fASD =~ fHOC
RAADS14 ~~ AQ10
MCQ_EMO ~~ MCQ_CAT'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = TRUE)
summary(OneSystem.fit, fit.measures = TRUE)
coef(OneSystem.fit)
# merge wide dataset
bigData <- data.frame(AQ10, RAADS14, BCIS15,MCQ_CAT, MCQ_EMO, META)
# skip rows with NaNs
bigData_clean <- na.omit(bigData)
# exclude outliers
bigData_clean2 <- rm.outlier(bigData_clean, fill = TRUE)
View(bigData_clean2)
# Meta Menta similar effect on ASD
OneSystemE.model <- 'fASD =~ AQ10 + RAADS14
fHOC =~ MCQ_EMO + MCQ_CAT + META
fASD =~ fHOC
RAADS14 ~~ AQ10
MCQ_EMO ~~ MCQ_CAT'
OneSystemE.fit <- sem(model = OneSystemE.model,
data = bigData_clean2,
std.lv = TRUE)
summary(OneSystemE.fit, fit.measures = TRUE)
# Meta Menta similar effect on ASD
OneSystem.model <- 'fASD =~ AQ10 + RAADS14
fHOC =~ MCQ_EMO + MCQ_CAT + META
fASD =~ fHOC
RAADS14 ~~ AQ10
MCQ_EMO ~~ MCQ_CAT'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = TRUE,
estimator = "MLM")
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
fit.measures = TRUE)
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
standardized = TRUE)
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = TRUE)
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = F)
View(bigData_clean2)
# standardize variables of interest
AQ10 <- scale(AQ10)
RAADS14 <- scale(RAADS14)
BCIS15 <- scale(BCIS15)
MCQ_CAT <- scale(MCQ_CAT)
MCQ_EMO <- scale(MCQ_EMO)
META <- scale(META)
# merge wide dataset
bigData <- data.frame(AQ10, RAADS14, BCIS15,MCQ_CAT, MCQ_EMO, META)
View(bigData)
# skip rows with NaNs
bigData_clean <- na.omit(bigData)
# exclude outliers
bigData_clean <- rm.outlier(bigData_clean, fill = TRUE)
# Meta Menta similar effect on ASD
OneSystem.model <- 'fASD =~ AQ10 + RAADS14
fHOC =~ MCQ_EMO + MCQ_CAT + META
fASD =~ fHOC
RAADS14 ~~ AQ10
MCQ_EMO ~~ MCQ_CAT'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = T)
summary(OneSystem.fit, fit.measures = TRUE)
# Meta Menta similar effect on ASD
OneSystem.model <- 'fASD =~ AQ10 + RAADS14
fHOC =~ MCQ_EMO + MCQ_CAT + META
fASD ~~ fHOC
RAADS14 ~~ AQ10
MCQ_EMO ~~ MCQ_CAT'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = T)
summary(OneSystem.fit, fit.measures = TRUE)
# Meta Menta similar effect on ASD
OneSystem.model <- 'fASD =~ AQ10 + RAADS14
fHOC ~~ MCQ_EMO + MCQ_CAT + META
fASD ~~ fHOC
RAADS14 ~~ AQ10
MCQ_EMO ~~ MCQ_CAT'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = T)
OneSystem.model <- '
fHOC =~ MCQ_EMO + MCQ_CAT + META
AQ10 ~~ fHOC
RAADS14 ~~ AQ10
MCQ_EMO ~~ MCQ_CAT'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = T)
# Meta Menta similar effect on ASD
OneSystem.model <- 'fHOC =~ MCQ_EMO + MCQ_CAT + META
RAADS14 ~~ AQ10
MCQ_EMO ~~ MCQ_CAT'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = T)
OneSystem.model <- 'fHOC =~ MCQ_EMO + MCQ_CAT
MCQ_EMO ~~ MCQ_CAT'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = T)
# Meta Menta similar effect on ASD
OneSystem.model <- 'fHOC =~ MCQ_EMO + MCQ_CAT
MCQ_CAT ~~ RAADS14'
OneSystem.fit <- sem(model = OneSystem.model,
data = bigData_clean2,
std.lv = T)
rm(list=ls())
require(R.matlab)
require(lme4)
require(car)
require(optimx)
require(ggplot2)
require(plyr)
require(lavaan) #for SEM
require(outliers) #to remove outliers and circumvent convergence problems w/ SEM
options(contrasts = c("contr.treatment", "contr.poly")) # This is R defaults but set it anyway to be safe
dat = NULL
AQ10 = NULL
AQ10_AD = NULL
AQ10_AS = NULL
AQ10_C = NULL
AQ10_I = NULL
AQ10_S = NULL
RAADS14 = NULL
RAADS14_MENTA = NULL
RAADS14_SOA = NULL
RAADS14_SOR = NULL
BCIS15 = NULL
BCIS_SR = NULL
BCIS_SC = NULL
MCQ_CAT = NULL
MCQ_EMO = NULL
META = NULL
fullIDs = NULL
sessions = c('v38', 'v39', 'v40', 'v41', 'v42', 'v43')
#load in all data
for (i in 1:length(sessions)){
currentData = paste('data_exp_12022-',sessions[i],sep="")
dataDir = "~/Dropbox/ASDTrait/Data/"
Dir = paste(dataDir,currentData, '/', sep="")
files = c('_task-pf6t', '_task-yzt9')
for (j in 1:length(files)){
data = read.csv2(paste(Dir, currentData, files[j],'.csv',sep=""), header=T, sep=",", )
dat = rbind(dat, data)
}
MATws = readMat(paste(Dir, 'ws_', sessions[i], '.mat', sep=""))
AQ10 = rbind(AQ10, MATws$AQ10)
RAADS14 = rbind(RAADS14, MATws$RAADS)
BCIS15 = rbind(BCIS15, t(MATws$BCIS))
AQ10_AD = rbind(AQ10_AD, MATws$AQ10.AD)
AQ10_AS = rbind(AQ10_AS, MATws$AQ10.AS)
AQ10_C = rbind(AQ10_C, MATws$AQ10.C)
AQ10_I = rbind(AQ10_I, MATws$AQ10.I)
AQ10_S = rbind(AQ10_S, MATws$AQ10.S)
RAADS14_MENTA = rbind(RAADS14_MENTA, MATws$MENTA)
RAADS14_SOA = rbind(RAADS14_SOA, MATws$SOA)
RAADS14_SOR = rbind(RAADS14_SOR, MATws$SOR)
BCIS_SR = rbind(BCIS_SR, t(MATws$BCIS.SR))
BCIS_SC = rbind(BCIS_SC, MATws$BCIS.SC)
MCQ_CAT = rbind(MCQ_CAT, t(MATws$MCQ.cat))
MCQ_EMO = rbind(MCQ_EMO, t(MATws$MCQ.feelings))
META = rbind(META, MATws$metaR)
IDs = read.csv2(paste(Dir, 'total_IDs_', sessions[i], '.csv', sep = ""), header = F, sep = ",", )
fullIDs = rbind(fullIDs, IDs)
}
i = 1
AQ10(i)
AQ10[i]
AQ10
sqrt(2)
length(AQ10)
mean(AQ10)
sum_diff = NULL
for (i in 1:length(AQ10)){
sum_diff = rbind(sum_diff, AQ10[i]- mean(AQ10, na.rm =T))
}
var = sqrt(sum_diff)/(length(AQ10) -1)
var
Q10 manually
AQ10 <- na.omit(AQ10)
AQ10 <- na.omit(AQ10)
mean(AQ10)
AQ10[i]
i = 1
AQ10[i]
sum_diff = NULL
for (i in 1:length(AQ10)){
sum_diff = rbind(sum_diff, AQ10[i]- mean(AQ10))
}
var = sqrt(sum_diff)/(length(AQ10) -1)
View(sum_diff)
(length(AQ10) -1)
var = (sum_diff^2)/(length(AQ10) -1)
var
mean(var)
sqrt(mean(var))
std(AQ10)
var(AQ10)
(sum_diff^2)
var = (sum_diff^2)/(length(AQ10) -1)
## cleans up and analyses online prolific data
## second code following the Main.m script
## elisavanderplasATgmail.com
rm(list=ls())
require(R.matlab)
require(lme4)
require(car)
require(optimx)
require(ggplot2)
require(plyr)
options(contrasts = c("contr.treatment", "contr.poly")) # This is R defaults but set it anyway to be safe
dat = NULL
AQ10 = NULL
AQ10_comm = NULL
RAADS14 = NULL
RAADS14_menta = NULL
MCQ_emo = NULL
fullIDs = NULL
sessions = c('v38', 'v39', 'v40', 'v41', 'v42', 'v43')
#load in all data
for (i in 1:length(sessions)){
currentData = paste('data_exp_12022-',sessions[i],sep="")
dataDir = "~/Dropbox/ASDTrait/Data/"
Dir = paste(dataDir,currentData, '/', sep="")
files = c('_task-pf6t', '_task-yzt9')
for (j in 1:length(files)){
data = read.csv2(paste(Dir, currentData, files[j],'.csv',sep=""), header=T, sep=",", )
dat = rbind(dat, data)
}
MATws = readMat(paste(Dir, 'ws_', sessions[i], '.mat', sep=""))
AQ10 = rbind(AQ10, MATws$AQ10)
AQ10_comm = rbind(AQ10_comm, MATws$AQ10.C)
RAADS14 = rbind(RAADS14, MATws$RAADS)
RAADS14_menta = rbind(RAADS14_menta, MATws$MENTA)
MCQ_emo = rbind(MCQ_emo, MATws$MCQ.feelings)
IDs = read.csv2(paste(Dir, 'total_IDs_', sessions[i], '.csv', sep = ""), header = F, sep = ",", )
fullIDs = rbind(fullIDs, IDs)
}
#scale ASD variables
fullIDs = t(fullIDs)
bigData = NULL
for (s in 1:length(fullIDs))
{
subj_dat = dat[dat$Participant.Private.ID==fullIDs[s],] ##load variables for specific subject
conftask_dat=subj_dat[subj_dat$Task_type=="simpleperceptual",]##select trials from the confidence sub-task
vistrials=conftask_dat[conftask_dat$label=="responsePerceptual",]##select initial binary decision (left/right) trials from the confidence sub-task
conftrials=conftask_dat[conftask_dat$label=="confidencerating",]##select subsequent confidence rating from the confidence sub-task
logRT = scale(log(vistrials$Reactiontime))
conf = round(as.numeric(conftrials$confidence_rating)*100)/100
keypress=vistrials$key_press
acc=vistrials$correct
acc[is.na(acc)]=0##accuracy==1: correct, accuracy==0: wrong
acc = acc-0.5##accuracy==0.5: correct, accuracy==-0.5: wrong
#have to ecompute objectively correct answer because js script doesn't give that
dir=rep(1, length(acc))
for (t in 1:length(acc)){
if (acc[t] ==1 & keypress[t] == 87){
dir[t]= -1}
else if (acc[t] == 0 && keypress[t]==69){
dir[t] = -1}
}##correct and chose left, dir == -1 (left) or wrong and chose right, dir == -1 (left)
#get all vars behind each other per subject
subj = rep(s, length(acc))
AQ=rep(AQ10[s], length(acc))
RAADS = rep(RAADS14[s], length(acc))
AQ_comm = rep(AQ10_comm[s], length(acc))
RAADS_menta = rep(RAADS14_menta[s], length(acc))
MCQ_emos = rep(MCQ_emo[s], length(acc))
subData1 = data.frame("subj"=subj, "dir"=dir,"AQ10"=AQ,"RAADS14"= RAADS,"AQ10_comm"=AQ_comm,"RAADS14_menta"= RAADS_menta, "acc"=acc, "conf"=conf, "logRT"=logRT, "MCQ_emo"=MCQ_emos)
#add to larger file
bigData = rbind(bigData, subData1)
}
# Factors
bigData$subj <- factor(bigData$subj)
# skip rows with NaNs
bigData_clean <- na.omit(bigData)
#Autistic traits
##RAADS
##conduct a hierarchical regression to see if interaction w/ AQ can explain how much confidence is influenced by standardized log RT
confModel_noRAADS = lmer(conf ~ acc + logRT + acc * logRT + (1 + acc + logRT|subj), data=bigData_clean
, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "bobyqa", starttests = FALSE, kkt = FALSE)))
confModel_wRAADS = lmer(conf ~ RAADS14*(acc + logRT + acc * logRT) + (1 + acc + logRT|subj), data=bigData_clean
, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "bobyqa", starttests = FALSE, kkt = FALSE, REML = FALSE)))
fix <- fixef(confModel_wRAADS)
print(summary(confModel_wRAADS))
print(Anova(confModel_wRAADS, type = 3))
coef(summary(confModel_wRAADS)) #get the contrast statistics
fix.se <- sqrt(diag(vcov(confModel_wRAADS))) ## 2-way interaction, no 3 way interaction, line 463 & 471
##supplementary materials = AQ10
##conduct a hierarchical regression to see if interaction w/ AQ can explain how much confidence is influenced by standardized log RT
confModel_noAQ = lmer(conf ~ acc + logRT + acc * logRT + (1 + acc + logRT|subj), data=bigData_clean
, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "bobyqa", starttests = FALSE, kkt = FALSE)))
confModel_wAQ = lmer(conf ~ AQ10*(acc + logRT + acc * logRT) + (1 + acc + logRT|subj), data=bigData_clean
, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "bobyqa", starttests = FALSE, kkt = FALSE, REML = FALSE)))
fix <- fixef(confModel_wAQ)
print(summary(confModel_wAQ))
print(Anova(confModel_wAQ, type = 3))
coef(summary(confModel_wAQ)) #get the contrast statistics
fix.se <- sqrt(diag(vcov(confModel_wAQ))) ## 2-way interaction, no 3 way interaction, line 463 & 471
## check if including AQ trials as interaction improved the fit of the model
anova(confModel_noAQ,confModel_wAQ)
## cleans up and analyses online prolific data (experiment 1)
## elisavanderplasATgmail.com
rm(list=ls())
require(R.matlab)
require(lme4)
require(car)
require(optimx)
require(ggplot2)
require(plyr)
require(readr)#to easily read csv's
options(contrasts = c("contr.treatment", "contr.poly")) # This is R defaults but set it anyway to be safe
dat=NULL #initiate vars to load
fullIDs=NULL
sessions = c('v38', 'v39', 'v40', 'v41', 'v42', 'v43')
#load in all task data
for (i in 1:length(sessions)){
currentData = paste('data_exp_12022-',sessions[i],sep="")
dataDir = "~/Dropbox/MetaMenta/Data/Exp1/"
Dir = paste(dataDir,currentData, '/', sep="")
files = c('_task-pf6t', '_task-yzt9')
for (j in 1:length(files)){
data = read.csv2(paste(Dir, currentData, files[j],'.csv',sep=""), header=T, sep=",", )
dat = rbind(dat, data)
}
IDs = read.csv2(paste(Dir, 'total_IDs_', sessions[i], '.csv', sep = ""), header = F, sep = ",", )
fullIDs = rbind(fullIDs, IDs)
}
#get the demographics
setwd(dataDir)
subData <- read_csv('data.csv')
#prepare the meta-task data
fullIDs = t(fullIDs)
bigData = NULL
for (s in 1:length(fullIDs))
{
subj_dat = dat[dat$Participant.Private.ID==fullIDs[s],] ##load variables for specific subject
conftask_dat=subj_dat[subj_dat$Task_type=="simpleperceptual",]##select trials from the confidence sub-task
vistrials=conftask_dat[conftask_dat$label=="responsePerceptual",]##select initial binary decision (left/right) trials from the confidence sub-task
conftrials=conftask_dat[conftask_dat$label=="confidencerating",]##select subsequent confidence rating from the confidence sub-task
logRT = scale(log(vistrials$Reactiontime))
conf = round(as.numeric(conftrials$confidence_rating)*100)/100
keypress=vistrials$key_press
acc=vistrials$correct
acc[is.na(acc)]=0##accuracy==1: correct, accuracy==0: wrong
acc = acc-0.5##accuracy==0.5: correct, accuracy==-0.5: wrong
#have to ecompute objectively correct answer because js script doesn't give that
dir=rep(1, length(acc))
for (t in 1:length(acc)){
if (acc[t] ==1 & keypress[t] == 87){
dir[t]= -1}
else if (acc[t] == 0 && keypress[t]==69){
dir[t] = -1}
}##correct and chose left, dir == -1 (left) or wrong and chose right, dir == -1 (left)
#get all vars behind each other per subject
subj = rep(s, length(acc))
AQ=rep(subData$AQ10[s], length(acc))
RAADS = rep(subData$RAADS[s], length(acc))
AQ_comm = rep(subData$AQ10_C[s], length(acc))
RAADS_menta = rep(subData$RAADS_MENTA[s], length(acc))
MCQ_emos = rep(subData$MCQ_feelings[s], length(acc))
subData1 = data.frame("subj"=subj, "dir"=dir,"AQ10"=AQ,"RAADS14"= RAADS,"AQ10_comm"=AQ_comm,"RAADS14_menta"= RAADS_menta, "acc"=acc, "conf"=conf, "logRT"=logRT, "MCQ_emo"=MCQ_emos)
#add to larger file
bigData = rbind(bigData, subData1)
}
# Factors
bigData$subj <- factor(bigData$subj)
# skip rows with NaNs
bigData_clean <- na.omit(bigData)
# get median-split on RAADS
RAADS_med <- median(bigData_clean$RAADS14)
bigData_clean$RAADSbi = cut(as.numeric(bigData_clean$RAADS14),breaks=c(0,RAADS_med,42),include.lowest=T, labels=c("low", "high"))
bigData_clean$RAADSbi <- factor(bigData_clean$RAADSbi)
## distinguish between error/correct & high vs. low autism trials
bigData_err <- bigData_clean[bigData_clean$acc == -0.5, ]
bigData_corr <- bigData_clean[bigData_clean$acc == 0.5, ]
bigData_lASDerr <- bigData_err[bigData_err$RAADSbi == "low", ]
bigData_hASDerr <- bigData_err[bigData_err$RAADSbi == "high", ]
bigData_lASDcorr <- bigData_corr[bigData_corr$RAADSbi == "low", ]
bigData_hASDcorr <- bigData_corr[bigData_corr$RAADSbi == "high", ]
##MCQ_emo
##conduct a hierarchical regression to see if interaction w/ MCQ can explain how much confidence is influenced by standardized log RT
confModel_noMCQ = lmer(conf ~ acc + logRT + acc * logRT + (1 + acc + logRT|subj), data=bigData_clean
, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "bobyqa", starttests = FALSE, kkt = FALSE, REML = FALSE)))
confModel_wMCQ = lmer(conf ~ MCQ_emo*(acc + logRT + acc * logRT) + (1 + acc + logRT|subj), data=bigData_clean
, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "bobyqa", starttests = FALSE, kkt = FALSE, REML = FALSE)))
fix <- fixef(confModel_wMCQ)
print(summary(confModel_wMCQ))
print(Anova(confModel_wMCQ, type = 3))
coef(summary(confModel_wMCQ)) #get the contrast statistics
fix.se <- sqrt(diag(vcov(confModel_wMCQ))) ##line 463 & 471
## check if including MCQ as interaction improved the fit of the model
anova(confModel_noMCQ,confModel_wMCQ)
250329-250347
250467-250448
-125149--125162
250299-250325
# get median MCQ
MCQ_med <- median(bigData_clean$MCQ_emo)
bigData_clean$MCQbi = cut(as.numeric(bigData_clean$MCQ_emo),breaks=c(0,MCQ_med,42),include.lowest=T, labels=c("low", "high"))
bigData_clean$MCQbi <- factor(bigData_clean$MCQbi)
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("#E69F00", "#56B4E9")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.4) +
labs(y="Confidence", x = "logRT (z-score)", color = "mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=18))
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("#E69F00", "#56B4E9")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.4) +
labs(y="Confidence", x = "logRT (z-score)", color = "mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=25))
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("palevioletred", "#56B4E9")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.4) +
labs(y="Confidence", x = "logRT (z-score)", color = "mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=25))
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("palevioletred1", "#56B4E9")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.4) +
labs(y="Confidence", x = "logRT (z-score)", color = "mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=25))
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("salmon", "turquoise3")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.4) +
labs(y="Confidence", x = "logRT (z-score)", color = "mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=25))
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("salmon", "turquoise3")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.2) +
labs(y="Confidence", x = "logRT (z-score)", color = "mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=25))
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("salmon", "turquoise3")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.2) +
labs(y="Confidence", x = "logRT (z-score)", color = "mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=25))
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("salmon", "turquoise3")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.2) +
labs(y="Confidence", x = "logRT (z-score)", color = "Mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=25))
#make a nice figure of conf~RTxRAADS interaction
ggplot(bigData_clean, aes(x=logRT, y=conf, colour=MCQbi)) +
geom_count() +
scale_color_manual(values=c("salmon", "turquoise3")) +
geom_point(shape=19, size=0.5, alpha = 1.0) +
geom_smooth(method="lm", se = T, aes(fill=MCQbi), alpha = 0.2) +
labs(y="Confidence", x = "logRT (z-score)", color = "Mentalizing efficiency") +
theme_minimal() + theme(axis.text=element_text(size=18),axis.title=element_text(size=25))
#Autistic traits
##RAADS
##conduct a hierarchical regression to see if interaction w/ AQ can explain how much confidence is influenced by standardized log RT
confModel_noRAADS = lmer(conf ~ acc + logRT + acc * logRT + (1 + acc + logRT|subj), data=bigData_clean
, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "bobyqa", starttests = FALSE, kkt = FALSE)))
confModel_wRAADS = lmer(conf ~ RAADS14*(acc + logRT + acc * logRT) + (1 + acc + logRT|subj), data=bigData_clean
, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "bobyqa", starttests = FALSE, kkt = FALSE, REML = FALSE)))
fix <- fixef(confModel_wRAADS)
print(summary(confModel_wRAADS))
print(Anova(confModel_wRAADS, type = 3))
coef(summary(confModel_wRAADS)) #get the contrast statistics
fix.se <- sqrt(diag(vcov(confModel_wRAADS))) ## 2-way interaction, no 3 way interaction, line 463 & 471
## check if including AQ trials as interaction improved the fit of the model
anova(confModel_noRAADS,confModel_wRAADS)
250479-250448
-125155--125162
250310-250325
